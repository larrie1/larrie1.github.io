/**
 *  English Translations
 *  Most of the translations got translated by Google
 *  (Level Descriptions (levelX_description) got AI generated)
 */
export const en = {
    title: 'Decision Trees',
    subtitle: 'A learning tool for understanding decision trees',
    footer: 'Designed and developed by Andr√© Peters',
    game: 'Game',
    node: 'Node',
    node_decision: 'Feature: ',
    node_value: 'Value ',
    generator: 'Generator',
    result: 'Prediction',
    lv2Decision: 'How is the Weather',
    hot: 'Hot',
    windy: 'Windy',
    rainy: 'Rainy',
    lv3Decision: 'Play Tennis',
    outlook: 'Outlook',
    temperature: 'Temperature',
    humidity: 'Humidity',
    no: 'No',
    yes: 'Yes',
    sunny: 'Sunny',
    overcast: 'Overcast',
    cool: 'Cool',
    mild: 'Mild',
    high: 'High',
    normal: 'Normal',
    bad_weather: 'Bad weather',
    good_weather: 'Good weather',
    check_code: 'Check code',
    clear_workspace: 'Clear workspace',
    show_tree: 'Show tree graph',
    reset: 'Reset',
    back: 'Back',
    next: 'Next',
    show_result: 'Show result',
    level3_decision: 'Which animal?',
    feathers: 'Has feathers?',
    fly: 'Can fly?',
    ground: 'Lives underground?',
    mole: 'Mole',
    dog: 'Dog',
    penguin: 'Penguin',
    crow: 'Crow',
    leaf_tooltip: 'This is a leaf, it represents your Decision',
    node_tooltip: 'This is a Node it connects with other Nodes or Leafs',
    level1_description: 'Once upon a time, there was a man named Max who owned a car and a motorcycle. One day, he had an accident and couldn\'t remember which vehicle he was driving. All he could recall was the number of tires. He knew that the vehicle had either four or two tires. Max asked his friend Tom for help. Tom was an expert in decision trees and assisted Max in creating a decision tree to determine which vehicle he was driving. Tom asked Max, "Does the vehicle have four tires?" Max replied, "Yes." Tom said, "Then you are driving the car." However, if Max had answered "No," Tom would have asked him, "Does the vehicle have two tires?" If Max had responded "Yes," Tom would have said, "Then you are riding the motorcycle."',
    level1_task: 'The task is as follows: Use the "tire" feature to determine which vehicle matches which properties. Check your tree if you are sure!',
    leaf_missing: 'Leaf is missing!',
    node_missing: 'Decision is missing!',
    block_intro_1: 'May we introduce: Your tool for the coming levels. This is the regular block to build a decision tree. You will have to use it for all levels.',
    not_again: 'Do not show again',
    block_intro_2: 'At this point in the block, you can choose what the block should represent. In this case, the block represents the feature "Hot". Using the drop-down menu that appears when you press the arrow, you can choose one of the given features for the block to represent. Each block can represent a maximum of one feature.',
    block_intro_title: 'Introduction: Block',
    block_intro_4: 'By default, the block "only" has two values, but you\'ll notice that you sometimes need more than one value. To expand the block for this there is the plus icon at the top left corner of the block. If you press on this you can expand the node by one value. After that, a minus symbol will also appear to remove the last value added.',
    block_intro_3: 'Here you can select one of the given options. There can be different number of values, so you should expand the block to cover all values. If you use a value twice, only the bottom value within the block will be evaluated. For this reason, only record each election once.',
    block_intro_5: 'The block is structured like a puzzle piece, you can add a so-called parent block to this block in the upper left corner. The parent block\'s feature is relevant to the child block, since the data has already been split by it. You can add this block to the parent block by simply dragging it to the value you want to connect it to and dropping it once they have connected.',
    block_intro_6: 'These are the bindings of your block. At this point, you can assign your values to a following block, which further divides the data or you assign it to a leaf. To do this, simply drag the block to the point with the connecting piece from the upper left corner of the block to be connected.',
    block_intro_7: 'With the help of this block you can represent a leaf of the tree, i.e. a decision. Only the decision blocks that represent a decision from the task are made available to you. You can connect this to a node using the connector on the left.',
    block_intro_8: 'This is what a tree could look like when you represent it using the blocks. At the moment this block represents the feature "Hot". If it is Hot, i.e. "Choice 1" is "true", then the decision "Good weather" has been made. Likewise with "Choice 2" and "false" the decision "Bad weather" was made. Have fun creating your first decision trees!',
    done: 'done',
    show_json: 'Show code',
    analyse_title: 'Analyse: Block',
    advice: 'Advice',
    json_error: 'No contiguous tree',
    target: 'Decision',
    tires: 'Tires',
    car: 'Car',
    motorcycle: 'Motorcycle',
    level1_decision: 'Which Vehicle?',
    level5_description: 'Once upon a time, there was a passionate tennis player named Sarah. She loved nothing more than hitting the court and playing a few sets with her friends. However, Sarah knew that certain weather conditions could impact her game. One sunny morning, Sarah woke up and checked the weather app on her phone. She saw that the temperature was 85 degrees Fahrenheit, the humidity was 70%, the wind was 8 miles per hour, and the outlook was partly cloudy. Sarah knew that these factors could either make or break her tennis game. She started to think about her preferences for each of these factors. She didn\'t mind playing in warm weather, but 85 degrees might be pushing it. She preferred the humidity to be lower than 60%, and the wind to be no more than 5 miles per hour. As for the outlook, she didn\'t mind playing in partly cloudy conditions, but she preferred a sunny day. So Sarah decided to make a decision based on her preferences. She checked the temperature and saw that it was a bit too hot for her liking. The humidity was also a bit high, and the wind was stronger than she preferred. She looked at the outlook and saw that it was partly cloudy. After considering all of these factors, Sarah decided to skip tennis for the day. She knew that the weather conditions could make it difficult to play her best game, and she didn\'t want to risk injury or frustration. Instead, she opted to stay home, relax, and plan to play tennis another day when the weather was more to her liking.',
    level5_task: 'Try to help Sarah and create a Decision Tree that predicts her Decision!',
    level2_description: 'A variety of fruits and vegetables grow in a beautiful garden called "Flavourful". This garden is maintained by a clever and curious botanist named Max. Max wants to help visitors to the garden distinguish fruit and vegetables based on their taste. So one day Max decided to create a decision tree to help his customers choose fruit and vegetables.',
    level2_task: 'The task is as follows: Max is just a botanist and doesn\'t know much about decision trees. Help him and create a decision tree for him that distinguishes "fruit" from "vegetables".',
    level3_description: 'Four animals are being studied in a research laboratory: a raven, a penguin, a mole and a dog. Each of these animals has different characteristics and abilities that set them apart from the other animals. The researchers want to use a decision tree to find out which animal can fly, which lives underground and which has feathers.',
    level3_task: 'The task is as follows: using the characteristics "feathers", "flies" and "life under the earth", determine which animal belongs to which properties. Is the given decision tree sufficient to clearly distinguish between the animals? If necessary, add further decisions. Check your tree if you are sure!',
    level4_description: 'In a small village called Sonnenheim lives a weather fairy named Luna. Luna has the special gift of being able to predict the weather and helping the people of Sunhome plan their activities accordingly. One morning Luna wakes up and looks out the window. She notices the sun is shining brightly in the sky and decides to let the villagers know if the weather would be good or bad. To make this decision, she wants to create a magic decision tree. This should decide what the weather is like based on the characteristics "Windy", "Rainy" and "Warm", so that Luna can also inform the villagers about the weather in the future!',
    level4_task: 'The task is as follows: help Luna complete her magic decision tree that can predict the weather to help the villagers.',
    level4_decision: 'What\'s the weather',
    level5_decision: 'Play Tennis',
    generator_description: 'This is the generator. He created your level based on the data you provided. This level has the same functionalities as the levels that have already been created. Using the ID3 machine learning algorithm, the generator can also provide you with a solution if you cannot solve your own level. Have fun solving your level!',
    level2_decision: 'Fruits or vegetables?',
    sweet: 'sweet',
    salty: 'salty',
    bitter: 'bitter',
    sour: 'sour',
    fruit: 'Fruit',
    vegetables: 'Vegetables',
    taste: 'Taste',
    random_test: 'Add random test',
    generator_step1: 'Please enter here which decision you would like to make with the help of the tree. It can be anything of your choice, but you cannot change your choice.',
    generator_step2: 'Here you can now add your features that determine which decision we decide on or how you can measure your decision. An example would be that you can tell a dog from a human based on fur.',
    generator_step3: 'Fill your table with life here! You should fill in all the parameters for each decision.',
    decision: 'Decision',
    features: 'Features',
    data: 'Data',
    generator_title: 'Create your own level!',
    valid_features: 'There are still unused features!',
    enough_features: 'Not enough features have been defined yet!',
    missing_data: 'Data is still missing in the table!',
    correct: 'Correct',
    incorrect: 'Wrong',
    guessed: 'Prediction',
    table: 'Table',
    darkmode: 'Lightning Mode',
    language: 'Language',
    level1_intro: 'This is the 1st level, it serves as a starting point to familiarize yourself with the block.',
    level2_intro: 'In this level the functionality of expanding a block should be learned & applied.',
    level3_intro: 'This level handles dividing the dataset into optimal subsets to get the most information.',
    level4_intro: 'Particular caution is required in this level, since not all data may provide information.',
    level5_intro: 'This is the 5th and final level, this is where your newly learned skills will be put to the test!',
    start_game: 'Here you can put your skills to the test, you are offered 5 different levels to create a decision tree. The tree is created using blocks, this is also explained to you there. Have a look!',
    start_generator: 'Here you can create your own level! First enter any data, the generator will create your level for you and then you can create a decision tree for your own data or have it created!',
    start_start: 'If you stay on this page you will be introduced to the basics of decision trees which will then help you in game to create a decision tree. Exactly the right choice for beginners!',
    info: 'Information',
    start: 'This is a prototype learning tool for learning decision trees. It can help you understand the basics and apply them. The application offers you three options to choose from. If you already know what decision trees are and how to create them, then you can skip this introduction and go straight to one of the two other options and put the theory into practice! However, if you are not familiar with the topic or would like to refresh your knowledge, then you should decide to stay here.',
    decide: 'Decide yourself...',
    decision_tree: 'Decision Tree',
    information_gain: 'Information gain',
    splits: 'Splits',
    machine_learning: 'Machine Learning',
    table_content: 'Table of contents',
    start_machine_learning: 'Machine learning is a sub-area of ‚Äã‚Äãartificial intelligence, which everyone should be familiar with after the release of ChatGPT. The term machine learning was introduced in 1959, but it was not used. Machine learning only became popular when spam filters used machine learning in the 1990s. Nowadays, machine learning is often used in modern computer science. And not without reason, there are many ways to use machine learning. Because when it comes to classifying something or determining a value, it makes sense to write a machine learning algorithm that classifies or predicts these values. Machine learning can be divided into three types, supervised, unsupervised and reinforcement learning. In reinforcement learning, the computer receives rewards or punishments when it solves or has solved a task. An attempt is made to learn the solution that has the greatest reward. In unsupervised learning, the computer does not receive any information about a desired solution based on rewards or the like. The computer has to use a data set to find patterns within this data and can then classify them. However, these types are not interesting for the decision trees, because these belong to the supervised learning. With supervised learning, the computer receives a result for training for each data set. The data is then classified into the possible classes. For example, if we go back to the spam filter example, ten different emails could constitute a training data set, with each of those emails already classified as spam or not spam. As a result, the computer learns characteristics that it can use to separate the e-mails from one another in the future.',
    start_decision_trees1: 'A decision tree represents a multi-step decision-making process with all decision options. Since the decision paths are depicted through individual branches, it is also referred to as a tree diagram. You can find a decision tree, as you will see in this learning tool, on the left side of this section. Such a tree is provided to you during programming so that you can visualize your program directly as a tree. The purpose of this decision tree is to arrive at a final decision based on various response options to specific questions. Just like natural trees, each decision tree has exactly one trunk. However, unlike natural trees, our decision trees grow downwards, so the trunk of the tree is at the top. It does not have any preceding decisions and therefore represents the first split in the dataset. During the game, you will be provided with a dataset that includes answers for each decision option and a decision corresponding to the given answers for the options. This means that based on an example from the dataset, you should be able to follow a path through the decision tree to reach a leaf. The leaf represents the final decision for the overarching question of the tree. The nodes represent the decision options, i.e., specific questions that affect the decision-making process. The possible answers to these decision options represent the respective features of the node. I believe the principle will become clearer to you through the following example.',
    start_decision_trees2: 'When you wake up in the morning, it is likely that you often find yourself standing in front of your wardrobe, wondering what to wear for the day. To make this decision, several decision options need to be considered, which affect the decision-making process. For example, if it is very hot outside, you certainly do not want to go out wearing a winter jacket. Therefore, we would like to create a decision tree to find the appropriate clothing. The most important question in this case is the question about the temperature, which will become our trunk. The two features, "Cold" and "Warm", represent the possible answers to the temperature question. If the temperature is "Warm", we should further inquire whether it is windy, because if it is, we would want to wear a sweater in addition to a T-shirt and shorts. If it is not windy, a T-shirt and shorts would suffice. On the other hand, if it is "Cold", we ask ourselves whether it is going to rain. If the answer is yes, we would wear a raincoat with our long pants, and if it is not going to rain anymore, a sweater would be enough. By utilizing these three questions, we were able to make a decision regarding our initial question.',
    start_splits: 'In our example from the previous chapter, you may have wondered why the question "What is the temperature?" was chosen as the trunk and why the subsequent questions were placed where they were. Let\'s assume that the dataset for the decision tree looks as depicted. We always try to divide the data into two equal-sized sets optimally, and in our example, that would be two sets with two leaves each for the first question. The question about the temperature precisely divides the data into such two sets: [Raincoat and long pants, sweater and long pants] and [sweater and shorts, T-shirt and shorts]. Therefore, it is a perfect choice for the trunk! Similarly, the questions "Is it raining?" and "Is it windy?" divide the subtree into two equal-sized sets of leaves. This data division is easy to understand in this example, but it becomes more challenging as the datasets grow larger. However, during programming, you will be assisted in determining the optimal divisions as these can also be calculated. The calculated values will be displayed to you as needed during the editing process. I will explain what these values represent and how they are calculated in the following chapters!',
    start_entropy: 'The entropy indicates how "impure" the data is. If the entropy is 1, the data is divided into equal-sized sets. However, if the entropy is 0, all data records belong to the same class. Values between 0 and 1 indicate that the data is unevenly distributed. If the entropy can only take values between 0 and 1, it has been normalized. You can see the mathematical formula for calculating entropy at the beginning of this chapter. Here, S represents the dataset, set A represents the possible decisions, and p(a) represents the distribution of the data points leading to that decision in relation to the entire dataset. Consequently, entropy provides a measure of the data distribution within a dataset. However, if we want to assess the difference in entropy resulting from a division, we need to consider the concept of information gain.',
    start_information_gain: 'The information gain represents how effectively a question divides the dataset when that question is used. Information gain can also take values between 0 and 1, where an information gain of 1 means that the dataset is divided into equal-sized sets. A value of 0 indicates that the dataset is not further divided by applying the respective question. Therefore, a high value for information gain is desirable for a question to optimally divide the dataset. The mathematical calculation of information gain is presented at the beginning of the chapter. Here, "a" represents a question, "Values(a)" represents the possible values that "a" can take, "S" represents the dataset, and "Sv" represents the subset of the dataset where question "a" has value "v".',
    entropy: 'Entropy',
    feature: 'Feature',
    hint: 'Hint',
    hint_title: 'Do you struggle with assigning a feature? Tell me which and I will try to help you!',
    hint_leafs: 'You have already made all the questions to find a decision, just choose the right Leaf! See the table with the data.',
    hint_description: 'In the following you can see the other decisions and their information gain, this can help you to find the optimal decision!',
    analyse: 'Great that you made this level! Below you can see statistics about your created decision tree. If you are not interested in the data or you want to continue, press the "X" in the upper right corner.',
    leaf: 'Leaf',
    root: 'Root',
    start_tree_decision: 'What should I wear today?',
    start_tree_temperature: 'What is the temperature?',
    start_tree_rain: 'Is it raining?',
    start_tree_windy: 'Is it windy?',
    start_tree_leaf1: 'Raincoat and long pants',
    start_tree_leaf2: 'Sweater and long pants',
    start_tree_leaf3: 'Raincoat and shorts',
    start_tree_leaf4: 'T-shirt and shorts',
    cold: 'cold',
    warm: 'warm',
    value: 'Value',
}